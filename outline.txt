===== Talk Outline =====

- Topic introduction
  - What is this talk about?
  - Who is this talk for?
  - What are we building?
  - What is an interpreter?
  - What does our language look like?
  - Why does our language look the way it does?
- What are languages?
- Why one might care about languages?
- What one might get out of learning about languages?
- Overview of an interpreter
- Tokenizer
  - Tokenizer generators
- Parser
  - BNF/EBNF
  - Parser generators
  - Top down parsers
  - Recursive descent parsers
- Evaluator
  - Pattern matching in Scala


Talking points:

- "We need these / We need this" maybe say something like the s-expression
  includes the intention

- "Parse function" "the parse function is like the Tokenizer function but we
  can operate with tokens"


Todo:

- DONE swap out variables and application slides. end with varaibles
- DONE after "those are s-expression" add "we'll come back to those"
- DONE there's a mistake with the identifier rule. also move it to the top
- DONE move sexpr rule to top of list
- DONE atom rule is wrong. should add string
- DONE "what if we had words instead" add "we need a lexer"
- DONE typo in lexer slide.
- DONE tokenizer function - split it into three slides adding the basic case
  statements first then the last ones later
- DONE tokenizer numbers = should be -
- DONE fix isIdentifier check
- DONE bad title in Tokenizer booleans
- DONE move None case to top in Tokenizer booleans
- DONE ASTs the ast is made up of explicit things like numbers and booleans but
  leaves other things to be implicit like parens and our data structures in our
  code need to mirror that.
- DONE Some changes to our Tokens split into two slides: implicit and explicit
- DONE Helper def for parseExpr - used "aux" but needs to be "parseExpr"
- DONE And now we have an AST - add indentation to bottom section
- DONE "Hey what about Lamba... " - remove so what is happening right now
- DONE Evaluate this! add example of calling lambda
